{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python notes: Data Collection  \n",
    "  \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection / Webscraping  \n",
    "  \n",
    "**Data Collection**  \n",
    "* Use a REST API\n",
    "* Sample the Right Data (Only get the relevant info)  \n",
    "> Only select the necessary features in the df\n",
    "> replace IDs with actual values if applicable\n",
    "* Fix formats\n",
    "> create dummy variables, change data types\n",
    "* Deal with Nulls \n",
    "\n",
    "**Webscraping**  \n",
    "* Identify the table of interest  \n",
    "* Iterate through th to get column names\n",
    "* iterate through tr and td to get info  \n",
    "  \n",
    "**Data Wrangling**  \n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>  \n",
    "  \n",
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime # represent date datatypes\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Data from a REST API endpoint\n",
    "\n",
    "url = 'paste endpoint URL here'\n",
    "\n",
    "response = requests.get(url) # save API response\n",
    "data = pd.json_normalize(response.json()) # store json as df\n",
    "\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter to set for a deeper inspection of the returned data\n",
    "\n",
    "# Setting this option will print all collumns of a dataframe\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Setting this option will print all of the data in a feature\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the Data\n",
    "\n",
    "data.head()\n",
    "data.shape()\n",
    "data.dtypes\n",
    "\n",
    "data.isnull().sum() # shows missing rows in each column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the Data\n",
    "\n",
    "data = data[[col1, col2, ..., colN]] # reassign the df to only inlcude the relevant columns  \n",
    "\n",
    "data = data[data['col'].map(function_to_select_characteristics)==condition] # reassign the df to only those which return true on the condition set; good for selecting rows of a specific value\n",
    "\n",
    "data['col'] = data['col'].map(lambda x : x[0]) # replaces values of lists with one item with the value itself; [1] -> 1\n",
    "\n",
    "data['date'] = pd.to_datetime(data['date']).dt.date # creates a new date column with the date data type, including only the date\n",
    "data = data[data['date'] <= datetime.date(yyyy, mm, dd)] # selects only rows that matches the date criteria\n",
    "\n",
    "data = data[data[filteredCol]==condition] # To filter rows based on meeting a condition given a column\n",
    "\n",
    "data.loc[:,'ID'] = list(range(1, data.shape[0]+1)) # reiterates the ordered sequence of number to uniquely identify the row; after cleaning, the data may start with not 1 and skip numbers, this will reset the count to 1 up to the last row\n",
    "\n",
    "data = data['col'].astypes('datatype') # change data type of a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with Nulls\n",
    "data.isnull.sum()\n",
    "\n",
    "# replace with mean\n",
    "mean = data['Col with Null'].mean()\n",
    "data['Col with Null'].replace(np.NaN, mean, inplace = True)\n",
    "\n",
    "# replace with most frequent value\n",
    "frequent = data['Col with Null'].value_counts().idxmax() \n",
    "data['Col with Null'].replace(np.NaN, frequent, inplace= True)\n",
    "\n",
    "# remove\n",
    "data.dropna(subset = ['Col with Null'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if some data are not actual values but rather id references for another API endpoint, define a function to append to an initialized global list \n",
    "\n",
    "\n",
    "\n",
    "# define function that will append the necessary info by using the ID to navigate to the right API endpoint\n",
    "def getData(data):\n",
    "    for x in data['colID']:\n",
    "            if x:\n",
    "                response = requests.get(\"URL\" + x).json()\n",
    "                feature__list1.append(response['feature1'])\n",
    "                ...\n",
    "                feature_listN.append(response['featureN'])\n",
    "\n",
    "            else:\n",
    "                feature__list1.append(None)\n",
    "                ...\n",
    "                feature_listN.append(None)\n",
    "\n",
    "\n",
    "# initialize empty list to append to\n",
    "feature_list1 = []\n",
    "...\n",
    "feature_listN = []\n",
    "\n",
    "\n",
    "# use function(s)\n",
    "getData(data)\n",
    "\n",
    "\n",
    "# create a dictionary to convert into a df\n",
    "new_dict = {'OrigData1': list(data['OrigData1']),\n",
    "'Date': list(data['date']),\n",
    "'Feature1':feature_list1,\n",
    "...\n",
    "'FeatureN':feature_listN}\n",
    "\n",
    "df = pd.DataFrame(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# lambda demonstration\n",
    "# lambda returns the results of the expression\n",
    "\n",
    "# lambda arguments : expression\n",
    "x = lambda a : a + 10\n",
    "print(x(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv for future use\n",
    "\n",
    "data.to_csv('Name.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the soup; confirm what tags the needed info is in\n",
    "\n",
    "url = 'URL here'\n",
    "response = requests.get(url, param = {'key':'value'}).text # param as needed by website; has to be the .text attribute of the json file to be able to convert into soup\n",
    "soup = BeautifulSoup(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soup verification\n",
    "\n",
    "soup.title # returns the title tags\n",
    "\n",
    "soup.tagOfInterest.string # returns the string content of a particular tag\n",
    "\n",
    "soup.prettify() # display html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find tags\n",
    "\n",
    "soup.find_all(name = 'tag', attr = 'attr looking for', string = 'string Content to find')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Remove an irrelvant column in dictionary\n",
    "del data_dict['Col']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets the column headers and assigns to dictionary to then fill\n",
    "\n",
    "def extract_column_from_header(row):\n",
    "    \"\"\"\n",
    "    This function returns the landing status from the HTML table cell \n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    # removes formatting tags\n",
    "    if (row.br):\n",
    "        row.br.extract()\n",
    "    if row.a:\n",
    "        row.a.extract()\n",
    "    if row.sup:\n",
    "        row.sup.extract()\n",
    "        \n",
    "    colunm_name = ' '.join(row.contents) # saves the column name as the output\n",
    "    \n",
    "    # Filters if column is empty; if condition can be changed to check for other parameters (formatting)\n",
    "    if column_name:\n",
    "        colunm_name = colunm_name.strip()\n",
    "        return colunm_name    \n",
    "\n",
    "\n",
    "\n",
    "column_names = []\n",
    "\n",
    "for th in table.tbody.find_all('th'): # return a list of all th tags in tbody of table\n",
    "\n",
    "    # Iterate each th element and apply the provided extract_column_from_header() to get a column name\n",
    "    column_name = extract_column_from_header(th)\n",
    "\n",
    "    # Append the non-empty column name into a list called column_names\n",
    "    if (column_name is not None) and (len(column_name) > 0):\n",
    "        column_names.append(column_name) # append the returned column_name from the extract_column_from_header\n",
    "\n",
    "\n",
    "\n",
    "# convert column names to keys for a dictionary\n",
    "data_dict= dict.fromkeys(column_names)\n",
    "\n",
    "# initialize each value as an empty list\n",
    "for i in column_names:\n",
    "    data_dict[i] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing through a table\n",
    "\n",
    "\n",
    "\n",
    "#Extract each table\n",
    "for table in enumerate(soup.find_all('table',\"string content\")):\n",
    "    \n",
    "   # get table rows for current table iteration \n",
    "    for rows in table.find_all(\"tr\"):\n",
    "            \n",
    "        #get each cell of the row \n",
    "        for index, cell in enumerate(rows.find_all('td')):\n",
    "\n",
    "            # First cell\n",
    "            data_dict[column_names[index]].append(cell.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dictionary to df\n",
    "\n",
    "df = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>  \n",
    "  \n",
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aea6fe521a8d4c902ca730e502c1a2f7b75abf53da708eec9ae2a041880e07b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
