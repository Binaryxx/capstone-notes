{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Notes: Modeling  \n",
    "<hr>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Preprocessing (Normalize)\n",
    "* Train Test Split\n",
    "> Grid Search then Test to find the best Parameteres\n",
    "* Apply Different Models\n",
    "* Evaluate\n",
    "> Metrics such as the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas is a software library written for the Python programming language for data manipulation and analysis.\n",
    "import pandas as pd\n",
    "# NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
    "import numpy as np\n",
    "# Matplotlib is a plotting library for python and pyplot gives us a MatLab like plotting framework. We will use this in our plotter function to plot data.\n",
    "import matplotlib.pyplot as plt\n",
    "#Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics\n",
    "import seaborn as sns\n",
    "# Preprocessing allows us to standarsize our data\n",
    "from sklearn import preprocessing\n",
    "# Allows us to split our data into training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Allows us to test parameters of classification algorithms and find the best one\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Logistic Regression classification algorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Support Vector Machine classification algorithm\n",
    "from sklearn.svm import SVC\n",
    "# Decision Tree classification algorithm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# K Nearest Neighbors classification algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y,y_predict):\n",
    "    \"this function plots the confusion matrix\"\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    cm = confusion_matrix(y, y_predict)\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')\n",
    "    ax.set_title('Confusion Matrix'); \n",
    "    ax.xaxis.set_ticklabels(['did not land', 'land']); ax.yaxis.set_ticklabels(['did not land', 'landed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert df to np array\n",
    "model_scores = {} # initialize list to store scores to determine best model later\n",
    "x = df.drop(\"Target\", axis = 1) # selects everything but the target column\n",
    "y = df[\"Target\"].to_numpy()\n",
    "#y = np.asarray(data[\"Target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize X\n",
    "x = preprocessing.StandardScaler().fit(x).transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit logreg model through gridsearch for best hyperparameters\n",
    "parameters = {\"C\":[0.01,0.1,1], 'penalty':['l2'], 'solver': ['lbfgs']} # lr parameters\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg_cv = GridSearchCV(logreg, parameters, cv = 10)\n",
    "logreg_cv.fit(x, y)\n",
    "\n",
    "model_scores[\"LogReg\"] = logreg_cv.score(x_test, y_test)\n",
    "\n",
    "yhat = logreg_cv.predict(x_test)\n",
    "\n",
    "\n",
    "print(\"tuned hpyerparameters: (best parameters)\", logreg_cv.best_params_)\n",
    "print(\"accuracy: \", logreg_cv.best_score_)\n",
    "print(\"test accuracy: \", logreg_cv.score(x_test, y_test))\n",
    "print(plot_confusion_matrix(y_test,yhat)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other models; follows the same format after initializing the object and the parameters to optimize\n",
    "\n",
    "# SVM\n",
    "parameters = {'kernel':('linear', 'rbf','poly','rbf', 'sigmoid'),\n",
    "              'C': np.logspace(-3, 3, 5),\n",
    "              'gamma':np.logspace(-3, 3, 5)}\n",
    "svm = SVC()\n",
    "\n",
    "# Decision Tree\n",
    "parameters = {'criterion': ['gini', 'entropy'],\n",
    "     'splitter': ['best', 'random'],\n",
    "     'max_depth': [2*n for n in range(1,10)],\n",
    "     'max_features': ['auto', 'sqrt'],\n",
    "     'min_samples_leaf': [1, 2, 4],\n",
    "     'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# KNN\n",
    "parameters = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "              'p': [1,2]}\n",
    "\n",
    "KNN = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterates through the models and returns the best models based on out of sample accuracy\n",
    "\n",
    "best_models_idx = []\n",
    "best_models = []\n",
    "\n",
    "for i, x in enumerate(model_scores.values()): \n",
    "    if x == max(model_scores.values()):\n",
    "        best_models_idx.append(i)\n",
    "\n",
    "for i, x in enumerate(model_scores.keys()):\n",
    "    if i in best_models_idx:\n",
    "        best_models.append(x)\n",
    "\n",
    "best_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aea6fe521a8d4c902ca730e502c1a2f7b75abf53da708eec9ae2a041880e07b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
